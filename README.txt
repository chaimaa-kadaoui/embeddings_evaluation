L'archive contient des matrices de cooccurrence, des embeddings pré-appris (HPCA, Word2vec et GloVe) ainsi qu'un script d'évaluation.

Les matrices de cooccurrence sont sous la forme de numpy.array, sauvegardés sous forme de texte via numpy.savetxt, puis compressés à l’aide de gzip. Aux fichiers compressés des matrices est associé un fichier "vocabulary.txt", avec un couple (mot, fréquence) par ligne, classés par ordre de fréquence décroissant, et dont l’ordre correspond aux lignes et aux colonnes des matrices. Les matrices de cooccurrences ont été calculées avec des fenêtres de contexte symétriques de "half_size" respective 2 et 5: on récupère les mots autour du mot central jusqu’à ce que l’on ait rempli la fenêtre, quitte à aller chercher plus loin si les mots les plus proches ne font pas partie du vocabulaire auquel on s’est restreint. Le corpus d’apprentissage est un dump du Wikiédia anglais datant du mois de mai 2016, tokenisé, mis en minuscule, et dont chaque occurrence de chiffre / nombre a été remplacée par le mot "NUMBER" (environ 14 Go non compressé).

Les embeddings HPCA ont été calculés directement à partir des matrices de cooccurrences ci-dessus. Pour les embeddings Word2Vec et GloVe, ceux-ci ont été appris avec les implémentations fournies par leurs auteurs à partir du même corpus textuel. Les détails du fenêtrage peuvent légèrement différer de celui décrit plus haut, mais les tailles de fenêtres sont bien les mêmes (2 et 5). Pour chaque type d'embeddings, deux dimensions de vecteurs sont fournies (50 et 200). Les embeddings sont dispos sous forme de fichier texte (compressé gunzip) avec un mot et son vecteur par ligne, séparé par des tabulations. Les informations relatives à chaque embeddings (half_size de la fenêtre, dimension) sont présentes dans le nom du fichier correspondant.

L’utilitaire d’évaluation des embeddings est un unique script python, avec le dosser "evaluation" contenant les fichiers nécessaires à l'évaluation. Pour charger un embedding à évaluer, on peut lui passer en paramètre soit le path vers un dossier contenant un fichier "vocabulary.txt" et un fichier "matrix.npy", soit un path vers un embedding sous forme de fichier texte avec un mot et son vecteur par ligne. On peut passer en paramètre plusieurs path de chaque type, afin de faire une comparaison des performances des embeddings. D’autres paramètres existent, détaillés en faisant "python script.py -h". Le tout est présent sous forme d’archive "embeddings_evaluation_utils.tar.gz" au même endroit que les embeddings et les matrices.
